## Convergence Predictions

_(Disclaimer: these are simply our initial notes: theories, intuitions, observations. Unlike our main essay, this treatment lacks a story / narrative structure. This topic will be one of the most imporant concepts to understand in a post AGI world... we haven't even scratched the surface of its depth)._

### What

Convergence is the phenomenon in which our activities evolve to be more complex _and_ more similar — towards a singular, highly complex, activity.

- “complex” =
- “similar” =

---

Activity is best represented as a recursive tree.

- Grows superexponentially in complexity. (we will explore why this is superexponential below).

---

Convergence is caused by advancement.

- Eating tree model.

AGI is a fundamentally different kind of advancement

- eating tree: balances.

Advancement is not just the technology. Technology alone doesn’t “eat” activities… people do. Unless people _act_ with the leverage on activities higher in the tree that are enabled, from which the downstream effects wipe out activities.

Leverage + incentives to use leverage + right beliefs all lead to advancement and impact our collective tree of activities. Any individual component without the others doesn’t have much impact.

Therefore, when we talk about “artificial intelligence” from here on out, we are talking about the change of artificial intelligence across the stories, instruments and technologies, not just about a specific technology (e.g. LLMs, etc.).

### Example: Creating a Startup

### Observations

---

Convergence occurs locally and globally.

But, eventually, **global becomes local.**

---

Convergence is accelerating _superexponentially_, not just because artificial intelligence is accelerating exponentially (which is a factor), but also due to the nature of convergence _itself_.

- As activities become more similar, far greater pool of competition and the faster the next "unlock" becomes.
- Incentives accelerate, stories accelerate, everything accelerates. Collectively accelerates crazy fast.

---

Convergence is not new.

---

Convergence _enables_ opportunities to do many activities through a single higher complexity activity.

---

Convergence leads to competition coming from _above_, not from the sides.

Only way to compete is to rise to higher complexity activities (higher in the tree of activities).

Thus, in a post AGI world, vision, courage, ambition, talent, become bottlenecks, not execution.

---

Convergence leads to a strong pressure to jump _upwards_, but also makes each jump upwards exponentially more difficult than the last. This difficulty is what causes extreme outcomes.

---

Convergence leads to delusion about the nature of an activity: its complexity and position in the global tree.

---

Convergence eliminates labels and boundaries between "domains".

---

Convergence will manifest in many ways:

- Convergence of outcomes: extreme outcomes.
- Convergence of geographical relevance: San Francisco, USA.
- Convergence of power: United States (hopefully).
- Convergence of platforms: The Foundation.
- Convergence of
- ***

---

As our activities become converge towards a singular activity, the notions of "domains" will dissolve. Though we are in the earliest days of artificial intelligence, we have already begun to witness this dissolution of boundaries locally. There has been a rapid convergence in roles within startups, and entirely new roles have emerged (product engineer, design engineer, etc.) that reflect convergence. Similarly, distinctions between startups, political organizations, science labs, film studios, etc. will also disappear. The phrase "starting a company" may not exist altogether. And, even if it does exist, it will mean something profoundly _different_ (and far more complex).
