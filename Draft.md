# Convergence

[homan](https://x.com/homanspirit) and [shiv](https://scholar.google.com/citations?user=WNUGEccAAAAJ&hl=en).

---

# ACT I — AGI

## Introduction

Artificial intelligence promises a future of abundance and prosperity in which each individual gains unimaginable power to realize their dreams.

Yet, we are far from *organizing* humanity in a way that enables us to take advantage of artificial intelligence towards prosperity instead of destruction.

To understand why we aren't organized to take advantage of artificial intelligence, we must first understand how artificial intelligence will change our world.

## How AGI changes our world

By Artificial *General* Intelligence (AGI) we mean an intelligence that can generally *reason* across any task as well as any human. And that this intelligence also sufficiently *embodied* such that it is capable of doing most physical tasks that humans do today (e.g. agriculture, assembly, delivery, etc.). We believe we will achieve full AGI sooner than expected, and that such AGI will amplify human potential, *not* replace the need for humans.

As artificial intelligence advances, our activities will *acceleratingly* evolve to become more ***complex*** (i.e., more possibilities within them) and more ***alike*** (i.e., being great at one will increasingly translate to being great at all).

**Outcomes in *all* activities will become increasingly *extreme***: at any given moment in time, a *smaller* percentage of individuals will be responsible for a *greater* share of economic value created — i.e., a *[power law distribution of outcomes](https://en.wikipedia.org/wiki/Power_law)*. The peak outcomes grow exponentially, while the median share falls.

**Rate of displacement of the winners accelerates.** Those who are generating the greatest outcomes will increasingly struggle to retain their dominance. *Churn* will accelerate.

**The absolute number of winners will grow**. Even though the distribution of outcomes will be far more extreme, since the peak outcomes grow exponentially, even *tiny* wins (relative to the peak wins) will still be massive. And since the rate of displacement accelerates, in a given period of time, there will be many more who would have touched success. We're already seeing early signs of this (todo).

**Artificial intelligence will enable *many* more activities than it will render unnecessary**. The range of activities we have witnessed throughout human history will eventually be a drop in the ocean of activities that will eventually exist. While it's impossible to predict the nature of these activities, we _can_ predict that they will be increasingly _similar_: i.e. ability in one will increasingly translates to ability in all, and that they will be highly complex with increasingly extreme outcomes.

- (todo: talk about how increasingly our imaginations and ability to see possibilities will be our biggest bottlenecks).

**Notions of separate domains and roles will dissolve**. As our activities become more complex and alike, rigidly defined domains and roles won't exist. We are seeing early signs of this: roles within startups are converging towards a singular "founder" role, and startups themselves are becoming much more than just "technology" companies. This means that the competition pool for roles and companies grows as ability transfers more easily across activities.

**Being outcompeted from *above* will be the norm.** Companies operating at higher levels of complexity will more quickly render more number of companies operating at lower levels of complexity unnecessary. For example: a more general robotics company will render many, many domains specific robotics companies (e.g. agriculture robotics company) obsolete. Previously, due to slow pace of change, domain specific companies had time to survive and thrive. As AGI rapidly advances, more niche companies will be rendered obsolete more quickly by a more general company (i.e., operating at a higher level of complexity) offering a competing service.

It will become exponentially more difficult to grow *upwards*: i.e start small and grow ambitious, forcing the most ambitious to *start* from above.

(todo: express notion that each "eat" from above will become bigger and bigger - due to being higher in the tree).

**Such change will accelerate.** It is not only technological advancement that causes such change. Any progress (more equal opportunity, better training, etc.) amplifies these changes. Even if AI progress halted for 5 years (unlikely), we would still see accelerating change because we've barely utilized the current technology itself.

---

AGI is a fundamentally different kind of advancement than we've ever seen because it cuts away activities below a certain complexity threshold, *across the board*. Previous advancements (such as computers, smartphones, internet, etc.) did not make less complex work in *all* domains irrelevant. Even as the reach of software and the internet grew, less complex work continued to exist in various domains (agriculture, supply chain, delivery, etc.).

In other words, previous advancements did not *force* *everyone* towards highly complex work. But, AGI does. It is this aggressive *universal* impact of AGI that elevates all human activity away from less complex work towards highly complex work — which have more extreme outcomes. 

Furthermore, an activity is best represented as a recursive tree with sub-activities of less complexity which each have more sub-activities. AGI pushes our activities *upwards* in this tree. Thus, activities increasingly become more alike (rigid boundaries dissolve) as a byproduct of the tree structure.

We call this phenomenon of in which our activities acceleratingly evolve to be more complex _and_ alike — towards a _highly complex_, _singular_ activity — **Convergence**[^convergence]. (note: in case you want to more thoroughly understand the underlying model that explains our predictions before proceeding, please read the more technical [convergence essay](./Convergence.md) and return).

[^convergence]: We believe Convergence is a fundamental phenomenon that not only explains how AGI will change our world, but also many other seemingly unrelated concepts (such as evolution, etc.).

---

Many activities we consider quite simple today, our ancestors found incredibly complex and difficult. Similarly, our close descendants will view many of our greatest challenges today as simple problems. Artificial intelligence will enable us to tackle problems that we previously thought were too complex to attack; from global warming, to health, to food and water scarcity, to space travel, etc. — promising a future of prosperity and abundance that we can't imagine.

But, without a fundamental re-organization of society, we will be needlessly crushed by AGI and will significantly delay (or fail) achieving the prosperity AGI promises.
## Problem

Rapid acceleration of artificial intelligence technology without sufficient acceleration of other facets of 

Advancement of AGI without advancement in other functions 

- Advancement of AGI *technology* makes our economic system oppressive because debt becomes an _unviable instrument_ to finance anything (i.e., our [problem](#problem)).
- Advancement in AGI _technology_ makes our education system oppressive because what people are learning will make them _unemployable_ in a post AGI world (i.e., our _stories_ are outdated).
- Advancement in AGI _technology_ makes our governance system oppressive because its rate of decision-making can’t keep up with rate of change (i.e., _governance instruments_ are outdated). For example, personal tokens will simply be a toy for the rich until UBE is implemented to ensure everyone has a stake in the collective growth.
- Advancement in AGI _technology_ makes our political climate oppressive because it lacks powerful stories of unity and collective growth that are now made possible due to artificial intelligence.
- _(and many many more)_.

- imbalance
- suffering
- examples of the many imbalances
- why they must be tackled together, as one, not separately.

# ACT II — Tokenization

# ACT III — Foundation